---
layout: blog
title: "Untrained Neural Networks and Emergent Properties"
date: 2025-02-20
categories: [Neural Networks, Research]
tags: [Neural Networks, Emergent Properties, Research]
image: /assets/images/placeholder.jpg
---

In our recent paper published in Scientific Reports, we made a fascinating discovery that challenges conventional wisdom in the field of artificial intelligence: even untrained neural networks can demonstrate abstract reasoning capabilities. This finding has profound implications for how we understand emergent properties in artificial intelligence systems and may help bridge the gap between artificial and biological neural networks.

## The Unexpected Capabilities of Untrained Networks

It's widely assumed that neural networks develop their impressive capabilities through extensive training on large datasets. The learning process—adjusting millions of connection weights through backpropagation—is considered essential for the network to perform complex tasks. However, our research reveals that certain core capabilities might be inherent to the architecture itself, emerging even without any training.

We designed an experiment where we presented neural networks with sequences of images containing various changing features. One of these features changed in a predictable pattern across the sequence. The networks' task was to identify this predictably changing feature among various other randomly changing elements—essentially a core component of abstract reasoning.

Surprisingly, even untrained networks with random weights performed significantly above chance level on this task. This suggests that the basic architecture of neural networks might inherently support certain forms of abstract pattern recognition without requiring weight optimization through learning.

> "The network's ability to extract abstract patterns without training suggests that certain cognitive capabilities might be more dependent on architecture than learning." — From our paper

## Implications for Understanding Intelligence

These findings challenge the strict dichotomy often drawn between "innate" and "learned" capabilities in both artificial and biological systems. Instead, they suggest a more nuanced view where architectural properties set the stage for certain capabilities that are then refined and enhanced through learning.

For AI research, this means that more attention should be paid to the inherent properties of network architectures, not just training algorithms and datasets. Some capabilities might be best achieved not through more extensive training but through thoughtful architectural choices.

For cognitive science, our findings provide a new perspective on the nature-nurture debate. Just as certain neural network architectures inherently support abstract reasoning without learning, biological neural circuits might similarly possess innate architectural properties that support core cognitive functions before experience-driven learning.

## Connecting to Scales of Description

This work ties directly to my broader research interest in scales of description in science. The emergent reasoning capabilities we observed represent a higher-level description (abstract pattern recognition) arising from a lower-level system (a randomly-initialized neural network). Understanding how different levels of description relate to each other is central to fields ranging from physics to cognitive science.

The framework of renormalization group theory from physics provides powerful tools for analyzing how properties at one scale relate to properties at another. In future work, we hope to formalize connections between this physics framework and the emergence of cognitive capabilities in neural systems.

## Looking Forward

Our findings open numerous directions for future research:

- What other cognitive capabilities might be inherent to neural network architectures?
- How do architectural properties and learning interact to produce more sophisticated capabilities?
- Can we design architectures specifically to enhance certain innate capabilities?
- What parallels exist between these findings and developmental psychology?

We're particularly excited about exploring the third research direction. If certain reasoning capabilities emerge naturally from specific architectural features, we might be able to design networks that inherently excel at abstract reasoning tasks without requiring extensive training—potentially leading to more efficient and explainable AI systems.

If you're interested in learning more, our [paper is available in Scientific Reports](https://www.nature.com/articles/s41598-024-78530-z), and the code for replicating our experiments is [available on GitHub](https://github.com/Tomer-Barak/learning-independent_abstract_reasoning).